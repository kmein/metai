{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0c2772-c87f-4ca1-bd21-d706e046635b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kristijono Donelaičio 'Metų' hegzametras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4367c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tabulate\n",
    "from  matplotlib.ticker import FuncFormatter\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option(\"styler.format.decimal\", \",\")\n",
    "pd.set_option(\"styler.format.precision\", 2)\n",
    "pd.set_option(\"styler.format.na_rep\", \"–\")\n",
    "cm = plt.cm.YlOrRd\n",
    "\n",
    "subdirectory = Path(\"assets\")\n",
    "subdirectory.mkdir(exist_ok=True)\n",
    "\n",
    "def write_figure(the_name):\n",
    "    plt.savefig(subdirectory / f\"figure-{the_name}.svg\")\n",
    "\n",
    "def write_table(df, the_name, caption=\"\", heatmap=False, axis=None):\n",
    "    style = df.style if not heatmap else df.style.background_gradient(axis=axis, cmap=cm)\n",
    "    with (subdirectory / f\"table-{the_name}.tex\").open(mode=\"w\") as f:\n",
    "        f.write(\n",
    "            (style).highlight_null(props=\"background-color:white; color:white;\").to_latex(\n",
    "                convert_css=True, \n",
    "                hrules=True,\n",
    "                sparse_index=False,\n",
    "                environment=\"longtable\", \n",
    "                position=\"!hbt\", \n",
    "                caption=caption, \n",
    "                label=\"tbl:\"+the_name\n",
    "            )\n",
    "        )\n",
    "    with (subdirectory / f\"table-{the_name}.html\").open(mode=\"w\") as f:\n",
    "        f.write((style).highlight_null(props=\"opacity:0\").to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429d10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_caesuras = [\"3h\", \"5h\", \"ktt\", \"7h\", \"pqt\", \"bd\"]\n",
    "df = pd.read_csv(os.getenv(\"EPIC_CSV\") or \"./metai-scansion.csv\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843bfd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_lines = df[df.isnull()[\"scansion\"]]\n",
    "df = df.dropna()\n",
    "print(len(incorrect_lines))\n",
    "incorrect_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4557e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous = df[\"scansion\"].str.contains(r'\\|')\n",
    "ambiguous_lines = df[ambiguous]\n",
    "df = df[~ambiguous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30622cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ambiguous_lines))\n",
    "print(len(df))\n",
    "for _, row in ambiguous_lines.iterrows():\n",
    "    print(str(row[\"book\"]) + \".\" + str(row[\"verse\"]) + \" (\" + row[\"scansion\"].replace(\"|\", \"/\") + \")\", end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a71fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df[\"scansion\"] = pd.Categorical(df[\"scansion\"], sorted(df[\"scansion\"].drop_duplicates().values, key=lambda x: x.count(\"S\")*2 + x.count(\"D\")*3))\n",
    "\n",
    "for caesura in all_caesuras:\n",
    "    df[caesura] = df[caesura].map({\"True\": True, \"False\": False})\n",
    "\n",
    "for column in [\"stressConflict\", \"metreConflict\", \"weightConflict\", \"syllables\", \"words\"]:\n",
    "    df[column] = df[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1bbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866e080-8ea7-432e-98d1-7f89002ec5ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How well does the analysis match the syllables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693ed8bc-405c-4caf-bc42-f0446db8f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"styler.format.precision\", 0)\n",
    "conflicts = df[[\"metreConflict\", \"stressConflict\", \"weightConflict\"]].apply(pd.Series.value_counts)\n",
    "conflicts.index = conflicts.index.rename(\"Konflikte\")\n",
    "conflicts = conflicts.rename({\"metreConflict\": \"Markierung\", \"stressConflict\": \"Wortakzent\", \"weightConflict\": \"Silbengewicht\"}, axis=\"columns\")\n",
    "write_table(conflicts, \"conflicts\", caption=\"Konflikte zwischen der Analyse und den metrischen Markierungen, dem Wortakzent und dem Silbengewicht\")\n",
    "pd.set_option(\"styler.format.precision\", 2)\n",
    "conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c211f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.metreConflict.astype(int).sum(), df.stressConflict.astype(int).sum(), df.weightConflict.astype(int).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2615f4d-a136-4a93-a690-ec45d2d1da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"weightConflict\"].astype(int).value_counts(\n",
    "df[df[\"weightConflict\"] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59907041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"stressConflict\"] >= 3) & (df[\"weightConflict\"] >= 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867372a-5d55-48d7-b8bc-3bf6547504d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Amount of syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67589e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables_per_word = df[\"syllables\"].sum() / df.words.sum()\n",
    "syllables_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf44d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables_per_verse = df[\"syllables\"].mean()\n",
    "print(df.syllables.std())\n",
    "syllables_per_verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7755e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syll / words\n",
    "syls_per_words = (df.groupby(\"book\")[\"syllables\"].sum() / df.groupby(\"book\")[\"words\"].sum()).rename(\"Silben / Wort\")\n",
    "average_sylls = df.groupby(\"book\")[\"syllables\"].mean().rename(\"μ Silben\")\n",
    "stddev_sylls = df.groupby(\"book\")[\"syllables\"].std().rename(\"σ Silben\")\n",
    "df_syllables = pd.concat([syls_per_words, average_sylls, stddev_sylls], axis=1)\n",
    "df_syllables.index = df_syllables.index.rename(\"Buch\")\n",
    "write_table(df_syllables, \"syllables\", caption=\"Silben pro Wort und Silben pro Vers\")\n",
    "df_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87bc9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby(\"book\")[\"syllables\"].value_counts()).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57835270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syllables[\"Silben / Wort\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d553fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllable count histogram\n",
    "ax = sns.histplot(y=\"syllables\", data=df, hue=\"book\", multiple=\"stack\")\n",
    "ax.set(ylabel='Anzahl Silben', xlabel='Anzahl Verse')\n",
    "ax.legend(title=\"Buch\", labels=[1,2,3,4])\n",
    "ax.set_yticks(sorted(list(df[\"syllables\"].drop_duplicates().values)))\n",
    "write_figure(\"syllable-count-histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0dcdf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syllables_count = pd.DataFrame(df[\"syllables\"].rename(\"Anzahl Verse\").value_counts())\n",
    "df_syllables_count.index = df_syllables_count.index.rename(\"Silbenzahl\")\n",
    "df_syllables_count[\"Anteil Verse/\\\\%\"] = 100 * df_syllables_count[\"Anzahl Verse\"] / len(df)\n",
    "write_table(df_syllables_count, \"syllable-count\", caption=\"Häufigkeit der einzelnen Silbenzahlen\")\n",
    "df_syllables_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51d4c7-3f6b-4c4a-8e06-c3c863a0f9bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20944027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(y=\"scansion\", data=df, hue=\"book\", multiple=\"stack\")\n",
    "ax.set(ylabel='Hexametertyp', xlabel='Anzahl Verse')\n",
    "ax.legend(title=\"Buch\", labels=[1,2,3,4])\n",
    "write_figure(\"scansion-histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e31a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"styler.format.precision\", 2)\n",
    "spondees_dactyls = pd.DataFrame()\n",
    "spondees_dactyls[\"Buch\"] = df[\"book\"]\n",
    "spondees_dactyls[\"S\"] = df[\"scansion\"].str.count(\"S\")\n",
    "spondees_dactyls[\"D\"] = df[\"scansion\"].str.count(\"D\")\n",
    "print(spondees_dactyls.sum(), spondees_dactyls.sum().D / (spondees_dactyls.sum().D + spondees_dactyls.sum().S))\n",
    "df_s_d = spondees_dactyls.groupby(\"Buch\").sum()\n",
    "df_s_d[\"Anteil D/\\\\%\"] = df_s_d[\"D\"] / (df_s_d[\"S\"] + df_s_d[\"D\"])\n",
    "write_table(df_s_d, \"dactyls-spondees\", caption=\"Daktylen vs. Spondeen\")\n",
    "df_s_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd388abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scansion = pd.DataFrame(df[\"scansion\"].rename(\"Anzahl Verse\").value_counts())\n",
    "df_scansion[\"Anteil Verse/\\\\%\"] = 100 * df_scansion[\"Anzahl Verse\"] / len(df)\n",
    "df_scansion.index = df_scansion.index.rename(\"Hexametertyp\")\n",
    "write_table(df_scansion, \"scansion-types\", caption=\"Häufigkeit einzelner Hexameter-Typen\")\n",
    "df_scansion[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac2393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spondiaci = df[df[\"scansion\"].str.endswith(\"SS\")]\n",
    "print(len(spondiaci), 100 * len(spondiaci) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2be6ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexameter_types = df.scansion.drop_duplicates().values\n",
    "print(hexameter_types)\n",
    "print([htype for htype in hexameter_types if htype.endswith(\"SS\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b8817a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['scansion'].rename(\"Hexametertyp\"), df['syllables'].rename(\"Silbenzahl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8927f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_verses = df[df[\"scansion\"].str.endswith(\"SSS\")][[\"book\", \"verse\", \"text\", \"scansion\"]]\n",
    "write_table(strange_verses, \"strange-verses\")\n",
    "strange_verses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c198d-541d-4252-92d0-56eebb637f61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Caesurae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abf7e1-fe8e-4a31-851b-5e807b996944",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Caesuras per book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb1df788",
   "metadata": {},
   "outputs": [],
   "source": [
    "caesura_rows = []\n",
    "for index, row in df.iterrows():\n",
    "    for caesura in all_caesuras:\n",
    "        if row[caesura] == True:\n",
    "            caesura_rows.append([row[\"book\"], row[\"verse\"], caesura])\n",
    "caesura_df = pd.DataFrame(caesura_rows, columns=[\"book\", \"verse\", \"caesura\"])\n",
    "caesura_df[\"caesura\"] = pd.Categorical(caesura_df[\"caesura\"], all_caesuras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7654c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caesura_per_book = pd.crosstab(caesura_df[\"book\"].rename(\"Buch\"), caesura_df[\"caesura\"].rename(\"Einschnitt\"))\n",
    "write_table(caesura_per_book, \"caesura-per-book\", caption=\"Häufigkeit einzelner Verseinschnitte (pro Buch)\")\n",
    "caesura_per_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efcc0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(x=\"caesura\", data=caesura_df, hue=\"book\", multiple=\"stack\")\n",
    "ax.set(xlabel='Einschnitt', ylabel='Anzahl Verse')\n",
    "ax.legend(title=\"Buch\", labels=[1,2,3,4])\n",
    "write_figure(\"caesura-histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aa2f528-a68d-44e7-9a2d-53e3615233a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reslut = []\n",
    "for s in all_caesuras:\n",
    "    count = df[s].value_counts()[True]\n",
    "    reslut.append([count, 100 * count / len(df)])\n",
    "caesura_count = pd.DataFrame(reslut, columns=[\"Anzahl Verse\", \"Anteil/\\\\%\"])\n",
    "caesura_count.index = all_caesuras\n",
    "caesura_count = caesura_count.sort_values(\"Anzahl Verse\", ascending=False)\n",
    "caesura_count.index = caesura_count.index.rename(\"Einschnitt\")\n",
    "write_table(caesura_count, \"caesura-count\", caption=\"Häufigkeit einzelner Verseinschnitte\")\n",
    "caesura_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6dbd3-8157-48d4-8d72-05e211da2008",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Caesura-less lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f7409f-698a-4f3c-8866-13fecfb18da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "caesuraless = df[~df[\"3h\"] & ~df[\"5h\"] & ~df[\"ktt\"] & ~df[\"7h\"] & ~df[\"pqt\"] & ~df[\"bd\"]]\n",
    "write_table(caesuraless, \"caesuraless\")\n",
    "caesuraless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdf227-ca93-4cd8-9968-d94874de7cff",
   "metadata": {},
   "source": [
    "### Caesura co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d6fbdef-e9ec-43d5-a7f5-fa1f85512732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "caesura_count = len(all_caesuras)\n",
    "occurrences = np.zeros((caesura_count+1, caesura_count+1))\n",
    "matrix = np.zeros((caesura_count))\n",
    "for idx, row in df[all_caesuras].iterrows():\n",
    "    for c1 in all_caesuras:\n",
    "        if row[c1] and not any(row[c2] for c2 in all_caesuras if c2 != c1):\n",
    "            i = all_caesuras.index(c1)\n",
    "            matrix[i] += 1\n",
    "    for c1, c2 in product(all_caesuras, all_caesuras):\n",
    "        if c1 == c2:\n",
    "            continue\n",
    "        i1, i2 = all_caesuras.index(c1), all_caesuras.index(c2)\n",
    "        if row[c1] and row[c2]:\n",
    "            occurrences[i1, i2] += 1\n",
    "occurrences[-1,:-1] = matrix\n",
    "occurrences[:-1,-1] = matrix\n",
    "occurrences = occurrences.astype(int)\n",
    "df_occ = pd.DataFrame(occurrences, index=all_caesuras + [\"keine\"], columns=all_caesuras + [\"keine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c54dc10-9b48-4370-8a06-e1eecfc4ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tril = df_occ.where(np.tril(np.ones(df_occ.shape), k=-1).astype(bool))\n",
    "pd.set_option(\"styler.format.precision\", 0)\n",
    "write_table(df_tril, \"cooccurrences\", caption=\"Häufigkeit des gemeinsamen Auftretens von Verseinschnitten\")\n",
    "df_occ\n",
    "#df_tril.style.format(precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a75519f9-cedf-4c33-b5dd-03c0a08ec453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df\n",
    "for caesura in all_caesuras:\n",
    "    df_copy[caesura] = df_copy[caesura].map({True: \"1\", False: \"0\"})\n",
    "df_caesura_combinations = pd.DataFrame(df_copy.groupby(all_caesuras).size().sort_values(ascending=False), columns=[\"Anzahl Verse\"])\n",
    "write_table(df_caesura_combinations, \"caesura-combinations\", caption=\"Häufigkeit der Kombinationen aus allen Verseinschnitten\")\n",
    "print(len(df_caesura_combinations))\n",
    "df_caesura_combinations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
